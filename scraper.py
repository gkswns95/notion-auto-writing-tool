# -*- coding: utf-8 -*-
"""
ë°±ì¤€ ë¬¸ì œ í¬ë¡¤ë§ ëª¨ë“ˆ

ë°±ì¤€ ì˜¨ë¼ì¸ ì €ì§€ í˜ì´ì§€ì—ì„œ ë¬¸ì œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""

import re
import requests
from bs4 import BeautifulSoup


def get_problem_id(url):
    """URLì—ì„œ ë¬¸ì œ ë²ˆí˜¸ ì¶”ì¶œ"""
    match = re.search(r'/problem/(\d+)', url)
    if match:
        return int(match.group(1))
    return None


def clean_text(text):
    """
    í…ìŠ¤íŠ¸ ì •ë¦¬: ê³¼ë„í•œ ì¤„ë°”ê¿ˆ ì œê±°
    ì—°ì†ëœ ì¤„ë°”ê¿ˆì„ í•˜ë‚˜ë¡œ ì¤„ì´ê³ , ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
    """
    if not text:
        return ""
    
    # ì—°ì†ëœ ì¤„ë°”ê¿ˆì„ í•˜ë‚˜ë¡œ
    text = re.sub(r'\n\s*\n', '\n\n', text)
    # 3ê°œ ì´ìƒ ì—°ì† ì¤„ë°”ê¿ˆì„ 2ê°œë¡œ
    text = re.sub(r'\n{3,}', '\n\n', text)
    # ì•ë’¤ ê³µë°± ì œê±°
    return text.strip()


def extract_images(element):
    """
    HTML ìš”ì†Œì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ
    
    Args:
        element: BeautifulSoup ìš”ì†Œ
    
    Returns:
        list: ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸
    """
    if not element:
        return []
    
    images = []
    for img in element.find_all("img"):
        src = img.get("src", "")
        if src:
            # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
            if src.startswith("//"):
                src = "https:" + src
            elif src.startswith("/"):
                src = "https://www.acmicpc.net" + src
            elif not src.startswith("http"):
                src = "https://www.acmicpc.net/" + src
            images.append(src)
    
    return images


def get_solved_ac_info(problem_id):
    """
    solved.ac APIì—ì„œ ë¬¸ì œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    
    Returns:
        dict: {tier: str, tier_level: int, tags: list}
    """
    result = {
        "tier": "Unknown",
        "tier_level": 0,
        "tags": []
    }
    
    try:
        response = requests.get(
            f"https://solved.ac/api/v3/problem/show",
            params={"problemId": problem_id},
            headers={"Accept": "application/json"}
        )
        
        if response.status_code == 200:
            data = response.json()
            level = data.get("level", 0)
            
            tier_names = {
                0: "Unrated",
                1: "Bronze V", 2: "Bronze IV", 3: "Bronze III", 4: "Bronze II", 5: "Bronze I",
                6: "Silver V", 7: "Silver IV", 8: "Silver III", 9: "Silver II", 10: "Silver I",
                11: "Gold V", 12: "Gold IV", 13: "Gold III", 14: "Gold II", 15: "Gold I",
                16: "Platinum V", 17: "Platinum IV", 18: "Platinum III", 19: "Platinum II", 20: "Platinum I",
                21: "Diamond V", 22: "Diamond IV", 23: "Diamond III", 24: "Diamond II", 25: "Diamond I",
                26: "Ruby V", 27: "Ruby IV", 28: "Ruby III", 29: "Ruby II", 30: "Ruby I"
            }
            
            result["tier"] = tier_names.get(level, "Unknown")
            result["tier_level"] = level
            
            # ì•Œê³ ë¦¬ì¦˜ íƒœê·¸ ì¶”ì¶œ
            tags = data.get("tags", [])
            for tag in tags:
                # í•œêµ­ì–´ íƒœê·¸ëª… ìš°ì„ , ì—†ìœ¼ë©´ ì˜ì–´
                display_names = tag.get("displayNames", [])
                ko_name = None
                en_name = None
                for name in display_names:
                    if name.get("language") == "ko":
                        ko_name = name.get("name")
                    elif name.get("language") == "en":
                        en_name = name.get("name")
                result["tags"].append(ko_name or en_name or tag.get("key", ""))
                
    except Exception as e:
        print(f"âš ï¸ solved.ac ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    
    return result


def scrape_problem(url):
    """
    ë°±ì¤€ ë¬¸ì œ í˜ì´ì§€ í¬ë¡¤ë§
    
    Args:
        url: ë°±ì¤€ ë¬¸ì œ URL (ì˜ˆ: https://www.acmicpc.net/problem/14716)
    
    Returns:
        dict: ë¬¸ì œ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    # ë¬¸ì œ ë²ˆí˜¸ ì¶”ì¶œ
    problem_id = get_problem_id(url)
    if not problem_id:
        raise ValueError(f"ì˜¬ë°”ë¥¸ ë°±ì¤€ URLì´ ì•„ë‹™ë‹ˆë‹¤: {url}")
    
    # Seleniumìœ¼ë¡œ í˜ì´ì§€ ë¡œë“œ (AWS WAF ìš°íšŒ)
    from selenium import webdriver
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from webdriver_manager.chrome import ChromeDriverManager
    
    chrome_options = Options()
    chrome_options.add_argument("--headless")  # ë¸Œë¼ìš°ì € ì°½ ìˆ¨ê¹€
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    
    try:
        driver.get(url)
        
        # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸° (ë¬¸ì œ ì œëª©ì´ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€)
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.ID, "problem_title"))
        )
        
        # HTML íŒŒì‹±
        soup = BeautifulSoup(driver.page_source, 'html.parser')
    finally:
        driver.quit()
    
    # ì œëª© ì¶”ì¶œ
    title_elem = soup.select_one("#problem_title")
    title = title_elem.text.strip() if title_elem else "ì œëª© ì—†ìŒ"
    
    # ë¬¸ì œ ì •ë³´ í…Œì´ë¸” ì¶”ì¶œ
    info_table = soup.select_one("#problem-info tbody tr")
    if info_table:
        cells = info_table.find_all("td")
        time_limit = cells[0].text.strip() if len(cells) > 0 else ""
        memory_limit = cells[1].text.strip() if len(cells) > 1 else ""
        submissions = cells[2].text.strip() if len(cells) > 2 else ""
        accepted = cells[3].text.strip() if len(cells) > 3 else ""
        users = cells[4].text.strip() if len(cells) > 4 else ""
        accuracy = cells[5].text.strip() if len(cells) > 5 else ""
    else:
        time_limit = memory_limit = submissions = accepted = users = accuracy = ""
    
    # ë¬¸ì œ ì„¤ëª… ì¶”ì¶œ
    description_elem = soup.select_one("#problem_description")
    description = clean_text(description_elem.get_text(separator="\n")) if description_elem else ""
    description_images = extract_images(description_elem)
    
    # ì…ë ¥ ì„¤ëª… ì¶”ì¶œ
    input_elem = soup.select_one("#problem_input")
    input_desc = clean_text(input_elem.get_text(separator="\n")) if input_elem else ""
    input_images = extract_images(input_elem)
    
    # ì¶œë ¥ ì„¤ëª… ì¶”ì¶œ
    output_elem = soup.select_one("#problem_output")
    output_desc = clean_text(output_elem.get_text(separator="\n")) if output_elem else ""
    output_images = extract_images(output_elem)
    
    # ì˜ˆì œ ì…ì¶œë ¥ ì¶”ì¶œ
    examples = []
    example_num = 1
    while True:
        sample_input = soup.select_one(f"#sample-input-{example_num}")
        sample_output = soup.select_one(f"#sample-output-{example_num}")
        
        if not sample_input:
            break
        
        examples.append({
            "input": sample_input.text.strip() if sample_input else "",
            "output": sample_output.text.strip() if sample_output else ""
        })
        example_num += 1
    
    # solved.ac ì •ë³´ ê°€ì ¸ì˜¤ê¸° (í‹°ì–´ + ì•Œê³ ë¦¬ì¦˜ íƒœê·¸)
    solved_info = get_solved_ac_info(problem_id)
    
    return {
        "problem_id": problem_id,
        "title": title,
        "tier": solved_info["tier"],
        "tier_level": solved_info["tier_level"],
        "tags": solved_info["tags"],
        "url": url,
        "time_limit": time_limit,
        "memory_limit": memory_limit,
        "submissions": submissions,
        "accepted": accepted,
        "users": users,
        "accuracy": accuracy,
        "description": description,
        "description_images": description_images,
        "input": input_desc,
        "input_images": input_images,
        "output": output_desc,
        "output_images": output_images,
        "examples": examples
    }


# í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
if __name__ == "__main__":
    import json
    
    test_url = "https://www.acmicpc.net/problem/14716"
    print(f"ğŸ” í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸: {test_url}\n")
    
    try:
        result = scrape_problem(test_url)
        print(json.dumps(result, indent=2, ensure_ascii=False))
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
